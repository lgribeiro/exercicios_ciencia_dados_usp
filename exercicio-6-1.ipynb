{"cells":[{"metadata":{},"cell_type":"markdown","source":"** exercicio 1 paramétrico **"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.stats import multivariate_normal\nfrom sklearn.metrics import accuracy_score\n\nrandom.seed(42) \n\ndata = pd.read_csv('../input/testecoracao/heart.csv', header=(0))\n\ndata = data.dropna(axis='rows') #remove NaN\n\n\nclasses = np.array(pd.unique(data[data.columns[-1]]), dtype=int)  \n\n\n# Converte para matriz e vetor do numpy\ndata = data.to_numpy()\nnrow,ncol = data.shape\ny = data[:,-1]\nX = data[:,0:ncol-1]\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(X)\nX = scaler.transform(X)\n\n\nprint('Media: ', np.mean(X, axis = 0))\nprint('Desvio Padrao:', np.std(X, axis = 0))\n\n\nfrom sklearn.model_selection import train_test_split\np = 0.8 # fracao de elementos no conjunto de treinamento\nx_train, x_test, y_train, y_test = train_test_split(X, y, train_size = p, random_state = 42)\n\nfrom scipy.stats import multivariate_normal\n\n\n#matrix to store the probabilities\nP = pd.DataFrame(data=np.zeros((x_test.shape[0], len(classes))), columns = classes) \n\nPc = np.zeros(len(classes)) #fraction of elements in each class\n\nfor i in np.arange(0, len(classes)): # Para cada classe\n    elements = tuple(np.where(y_train == classes[i])) # elmentos na classe i\n    Pc[i] = len(elements)/len(y_train) # Probabilidade pertencer a classe i\n    Z = x_train[elements,:][0] # Elementos no conjunto de treinamento\n    m = np.mean(Z, axis = 0) # Vetor media\n    cv = np.cov(np.transpose(Z)) # Matriz de covariancia\n    for j in np.arange(0,x_test.shape[0]): # para cada observacao no conjunto de teste\n        x = x_test[j,:]\n        # calcula a probabilidade pertencer a cada classe\n        pj = multivariate_normal.pdf(x, mean=m, cov=cv, allow_singular=True)\n        P[classes[i]][j] = pj*Pc[i]\n        \n        \ny_pred = [] # Vetor com as classes preditas\nfor i in np.arange(0, x_test.shape[0]):\n    c = np.argmax(np.array(P.iloc[[i]]))\n    y_pred.append(classes[c])\ny_pred = np.array(y_pred, dtype=int)\n# calcula a acuracia\nscore = accuracy_score(y_pred, y_test)\nprint('\\nAcuracia Bayesiano paramétrico:', score)","execution_count":1,"outputs":[{"output_type":"stream","text":"Media:  [ 4.69005106e-17 -1.40701532e-16  2.34502553e-17 -7.03507659e-16\n -1.11388713e-16 -2.34502553e-17  1.46564096e-16 -6.80057404e-16\n -4.69005106e-17  2.34502553e-17 -1.40701532e-16 -2.34502553e-17\n -1.64151787e-16]\nDesvio Padrao: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\nAcuracia Bayesiano paramétrico: 0.8360655737704918\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"exercicio 1 não paramétrico"},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KernelDensity\nfrom sklearn.metrics import accuracy_score\n\nrandom.seed(42)\ndata = pd.read_csv('../input/testecoracao/heart.csv', header=(0))\n\nclasses = np.array(pd.unique(data[data.columns[-1]]), dtype=int)  \n\n# Converte para matriz e vetor do numpy\ndata = data.to_numpy()\nnrow,ncol = data.shape\ny = data[:,-1]\nX = data[:,0:ncol-1]\n\n# Transforma os dados para terem media igual a zero e variancia igual a 1\nscaler = StandardScaler().fit(X)\nX = scaler.transform(X)\n\n# Seleciona os conjuntos de treinamento e teste\np = 0.8 # fraction of elements in the training set\nx_train, x_test, y_train, y_test = train_test_split(X, y, train_size = p, random_state = 42)\n\n# Matriz que armazena as probabilidades para cada classe\nP = pd.DataFrame(data=np.zeros((x_test.shape[0], len(classes))), columns = classes) \nPc = np.zeros(len(classes)) # Armaze a fracao de elementos em cada classe\nh = 2\nfor i in np.arange(0, len(classes)): # Para cada classe\n    elements = tuple(np.where(y_train == classes[i])) # elmentos na classe i\n    Pc[i] = len(elements)/len(y_train) # Probabilidade pertencer a classe i\n    Z = x_train[elements,:][0] # Elementos no conjunto de treinamento\n    kde = KernelDensity(kernel='gaussian', bandwidth=h).fit(Z)\n    for j in np.arange(0,x_test.shape[0]): # para cada observacao no conjunto de teste\n        x = x_test[j,:]\n        x = x.reshape((1,len(x)))\n        # calcula a probabilidade pertencer a cada classe\n        pj = np.exp(kde.score_samples(x)) \n        P[classes[i]][j] = pj*Pc[i]\n        \ny_pred = [] # Vetor com as classes preditas\nfor i in np.arange(0, x_test.shape[0]):\n    c = np.argmax(np.array(P.iloc[[i]]))\n    y_pred.append(classes[c])\ny_pred = np.array(y_pred, dtype=int)\n# calcula a acuracia\nscore = accuracy_score(y_pred, y_test)\nprint('Acuracia não-parametrico:', score)","execution_count":2,"outputs":[{"output_type":"stream","text":"Acuracia não-parametrico: 0.8852459016393442\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Exercicio 1 Naive-Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\n\nrandom.seed(42) \n\ndata = pd.read_csv('../input/testecoracao/heart.csv', header=(0))\n\nclasses = np.array(pd.unique(data[data.columns[-1]]), dtype=int)  \n\n# Converte para matriz e vetor do numpy\ndata = data.to_numpy()\nnrow,ncol = data.shape\ny = data[:,-1]\nX = data[:,0:ncol-1]\n\n# Transforma os dados para terem media igual a zero e variancia igual a 1\nscaler = StandardScaler().fit(X)\nX = scaler.transform(X)\n\n# Seleciona os conjuntos de treinamento e teste\np = 0.8 # fraction of elements in the test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = p, random_state = 42)\n\n# ajusta o classificador Naive-Bayes de acordo com os dados\nmodel = GaussianNB()\nmodel.fit(X_train, y_train)\n# realiza a predicao\ny_pred = model.predict(X_test)\n# calcula a acuracia\nscore = accuracy_score(y_pred, y_test)\nprint('Acuracia Naive-Bayes:', score)\n\n","execution_count":3,"outputs":[{"output_type":"stream","text":"Acuracia Naive-Bayes: 0.8688524590163934\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}